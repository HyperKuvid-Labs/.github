# HyperKuvid Labs

A small group(3) of students experimenting with LLMs, inference systems, RL, and CUDA. We build things to understand how they work, not to ship products.

## What We Do

We're focused on:
- LLM inference optimization and serving strategies
- Reinforcement learning for non-standard problems
- CUDA programming and GPU-level performance work
- Building end-to-end systems that combine multiple techniques

## Projects

**alphadesign** — Hybrid AI framework combining reinforcement learning and genetic algorithms to optimize Formula 1 front wing aerodynamic designs. Features neural network-guided optimization, CFD analysis, structural constraint validation, and F1 regulatory compliance checking for accelerated design iteration.

**frugalsot** — An adaptive model selection system for efficient on-device NLP inference, enhancing speed, privacy, and resource use on edge devices.

**phydra** — End-to-end cargo management system with advanced 3D bin packing algorithms, A*/Dijkstra pathfinding implemented in C++ for ISS applications.

**gideon** — Emotion-aware LLM chat interface with Ollama, FastAPI, and React, featuring real-time image generation and project automation via AlphaStack agent. Accelerates full-stack and blockchain dev by 60%, blending local/cloud models for empathetic, context-rich interactions.

**specquant** — Scalable framework for adaptive LLM serving: classify prompt complexity → select quantized drafts → verify with FP16 target, no model retraining required.

**alphastack** — A universal, AI-powered development agent that supports any tech stack—battle-tested across 25+ full dev cycles. It intelligently scaffolds and iterates on complex projects with automated feedback loops to accelerate software delivery.

## Contributing

If you're working on similar problems or have ideas worth testing, we're open to collaboration. Code-first, lightweight experiments preferred.
